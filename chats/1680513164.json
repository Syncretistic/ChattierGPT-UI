{"created": 1680513164, "frequency_penalty": 0.0, "max_context_tokens": 4000, "max_tokens": 4000, "messages": {"content": "You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.", "context_tokens": 0, "next": [{"content": "Write a GPT program that queries the api (we'll call it \"Writer agent\"), gets a response, then makes another query (to the Reviewer agent) that passes the response together with a phrase that tells gpt to review if the response met the original objectives. The response to this query, containing the critiques, is then passed again to the first Writer agent, which generates another response, which then is passed to the reviewer GPT and so on. The user must be able to set the number of repetitions of this cycle to the program. The objective is to make gpt critique itself and get better results.\n\nHere is the documentation for the chat completion api\n\nChat models take a series of messages as input, and return a model-generated message as output.\n\nAlthough the chat format is designed to make multi-turn conversations easy, it\u2019s just as useful for single-turn tasks without any conversations (such as those previously served by instruction following models like text-davinci-003).\n\nAn example API call looks as follows:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\nimport openai\n\nopenai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n    ]\n)\nThe main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message). Conversations can be as short as 1 message or fill many pages.\n\nTypically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.\n\nThe system message helps set the behavior of the assistant. In the example above, the assistant was instructed with \"You are a helpful assistant.\"\n\ngpt-3.5-turbo-0301 does not always pay strong attention to system messages. Future models will be trained to pay stronger attention to system messages.\nThe user messages help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.\n\nThe assistant messages help store prior responses. They can also be written by a developer to help give examples of desired behavior.\n\nIncluding the conversation history helps when user instructions refer to prior messages. In the example above, the user\u2019s final question of \"Where was it played?\" only makes sense in the context of the prior messages about the World Series of 2020. Because the models have no memory of past requests, all relevant information must be supplied via the conversation. If a conversation cannot fit within the model\u2019s token limit, it will need to be shortened in some way.\n\nResponse format\nAn example API response looks as follows:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n{\n 'id': 'chatcmpl-6p9XYPYSTTRi0xEviKjjilqrWU2Ve',\n 'object': 'chat.completion',\n 'created': 1677649420,\n 'model': 'gpt-3.5-turbo',\n 'usage': {'prompt_tokens': 56, 'completion_tokens': 31, 'total_tokens': 87},\n 'choices': [\n   {\n    'message': {\n      'role': 'assistant',\n      'content': 'The 2020 World Series was played in Arlington, Texas at the Globe Life Field, which was the new home stadium for the Texas Rangers.'},\n    'finish_reason': 'stop',\n    'index': 0\n   }\n  ]\n}\nIn Python, the assistant\u2019s reply can be extracted with response['choices'][0]['message']['content'].\n\nEvery response will include a finish_reason. The possible values for finish_reason are:\n\nstop: API returned complete model output\nlength: Incomplete model output due to max_tokens parameter or token limit\ncontent_filter: Omitted content due to a flag from our content filters\nnull: API response still in progress or incomplete\n\n The following is a breakdown of the actions\n\n1. Queries the Writer agent through the Chat Completion API with GPT-4 model with threestrings, which must be set up at the beginning of the code. \"Context\" and \"objectives\" must be included in the system message, while \"task\" will be passed as a user message.\n2. Extracts the response and passes it to the Reviewer agent, including only a system message composed of \"context\", \"objectives\" and another string called \"review_task\", and a user message containing only the response from the call to the Writer agent.\n3. Extracts the response from the Reviewer agent (the \"critique\") and makes a new call to the Writer agent, including as the user message the latest response that the writer agent gave together with the latest\"critique\", the context and objectives in the system message.\n4. The loop repeats.", "context_tokens": 28, "next": [{"content": "Here is a Python program that implements the described iterative process using OpenAI's ChatCompletion API:\n\n```python\nimport openai\n\ndef chat_gpt(agent, messages):\n    response = openai.ChatCompletion.create(\n        model=agent,\n        messages=messages\n    )\n    return response['choices'][0]['message']['content']\n\ndef iterative_improvement(writer_agent, reviewer_agent, context, objectives, task, review_task, iterations):\n    system_message = f\"You are a helpful assistant. {context} {objectives}\"\n\n    for i in range(iterations):\n        # Query Writer agent\n        writer_response = chat_gpt(writer_agent, [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": task}\n        ])\n\n        # Query Reviewer agent\n        critique = chat_gpt(reviewer_agent, [\n            {\"role\": \"system\", \"content\": f\"{system_message} {review_task}\"},\n            {\"role\": \"user\", \"content\": writer_response}\n        ])\n\n        # Update task with critique\n        task = f\"{writer_response} {critique}\"\n\n    return writer_response\n\n# Set variables\nwriter_agent = \"gpt-3.5-turbo\"\nreviewer_agent = \"gpt-3.5-turbo\"\ncontext = \"Context: ...\"\nobjectives = \"Objectives: ...\"\ntask = \"Task: ...\"\nreview_task = \"Review task: ...\"\niterations = 3\n\n# Call iterative_improvement function\nfinal_response = iterative_improvement(writer_agent, reviewer_agent, context, objectives, task, review_task, iterations)\nprint(final_response)\n```\nReplace \"Context: ...\", \"Objectives: ...\", \"Task: ...\", and \"Review task: ...\" with the relevant information. Make sure to have OpenAI Python v0.27.0 installed and your API key properly configured. This program will make GPT critique itself and improve its response iteratively.", "context_tokens": 1156, "next": [{"content": "where do you set the api key?", "context_tokens": 1565, "next": [{"content": "To set the API key, you can either set it as an environment variable or directly in your Python script. Here are both methods:\n\n1. Set the API key as an environment variable:\n\nFor Linux or macOS, open the terminal and run:\n\n```bash\nexport OPENAI_API_KEY=\"your_api_key_here\"\n```\n\nFor Windows, open the Command Prompt and run:\n\n```cmd\nset OPENAI_API_KEY=your_api_key_here\n```\n\nRemember to replace `your_api_key_here` with your actual API key.\n\n2. Set the API key directly in your Python script:\n\nBefore using the `openai` package, add the following line to your script:\n\n```python\nimport openai\n\nopenai.api_key = \"your_api_key_here\"\n```\n\nAgain, replace `your_api_key_here` with your actual API key. Keep in mind that sharing your script with others will expose your API key if you use this method, so use it with caution.", "context_tokens": 1578, "next": [{"content": "Ok. Are you sure all of this works?\n", "context_tokens": 1779, "next": [{"content": "I apologize for any confusion. There might be some limitations due to the nature of GPT-3.5-turbo not paying strong attention to system messages. This iterative improvement process might not produce significantly better results, as GPT-3.5-turbo might not be able to critique itself effectively.\n\nHowever, the provided Python code should work as a starting point for experimenting with the iterative process. You may need to adjust the context, objectives, and review tasks to elicit better responses from the model. Please ensure you have the OpenAI Python v0.27.0 library installed, your API key is configured, and you have sufficient API quota to perform multiple iterations. Remember that each API call consumes tokens, and many iterations may quickly exhaust your quota.\n\nLastly, the actual efficacy of this iterative process will depend on the specific tasks and context provided, as well as the models used for the Writer and Reviewer agents. You can experiment with different models, tasks, and context to see how well the process works for your specific use case.", "context_tokens": 1794, "next": [{"content": "how can I wrap it in a main function?", "context_tokens": 2011, "next": [{"content": "To wrap the provided code in a `main` function, simply define a new function called `main` and move the relevant code inside it. Then, call the `main` function at the end of the script. Here's the updated code:\n\n```python\nimport openai\n\ndef chat_gpt(agent, messages):\n    response = openai.ChatCompletion.create(\n        model=agent,\n        messages=messages\n    )\n    return response['choices'][0]['message']['content']\n\ndef iterative_improvement(writer_agent, reviewer_agent, context, objectives, task, review_task, iterations):\n    system_message = f\"You are a helpful assistant. {context} {objectives}\"\n\n    for i in range(iterations):\n        writer_response = chat_gpt(writer_agent, [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": task}\n        ])\n\n        critique = chat_gpt(reviewer_agent, [\n            {\"role\": \"system\", \"content\": f\"{system_message} {review_task}\"},\n            {\"role\": \"user\", \"content\": writer_response}\n        ])\n\n        task = f\"{writer_response} {critique}\"\n\n    return writer_response\n\ndef main():\n    openai.api_key = \"your_api_key_here\"\n\n    writer_agent = \"gpt-3.5-turbo\"\n    reviewer_agent = \"gpt-3.5-turbo\"\n    context = \"Context: ...\"\n    objectives = \"Objectives: ...\"\n    task = \"Task: ...\"\n    review_task = \"Review task: ...\"\n    iterations = 3\n\n    final_response = iterative_improvement(writer_agent, reviewer_agent, context, objectives, task, review_task, iterations)\n    print(final_response)\n\nif __name__ == \"__main__\":\n    main()\n```\n\nMake sure to replace `your_api_key_here` and the placeholder strings for context, objectives, task, and review task with the relevant information.", "context_tokens": 2026, "next": [], "role": "assistant", "selected": null, "tokens": 406}], "role": "user", "selected": 0, "tokens": 15}], "role": "assistant", "selected": 0, "tokens": 217}], "role": "user", "selected": 0, "tokens": 15}], "role": "assistant", "selected": 0, "tokens": 201}], "role": "user", "selected": 0, "tokens": 13}], "role": "assistant", "selected": 0, "tokens": 409}], "role": "user", "selected": 0, "tokens": 1128}], "role": "system", "selected": 0, "tokens": 28}, "model": "gpt-4", "presence_penalty": 0.0, "temperature": 0.7, "top_p": 1.0}